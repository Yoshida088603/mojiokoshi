import torch
from transformers import pipeline
import torchaudio
import numpy as np
import os
import time
import argparse

def transcribe_audio(input_file):
    print("Current working directory:", os.getcwd())
    print(f"Processing file: {input_file}")

    # コンフィグ設定
    model_id = "kotoba-tech/kotoba-whisper-v2.0"
    torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32
    device = "cuda:0" if torch.cuda.is_available() else "cpu"
    model_kwargs = {"attn_implementation": "sdpa"} if torch.cuda.is_available() else {}
    generate_kwargs = {"language": "japanese", "return_timestamps": True}

    print(f"Using device: {device}")
    print("Loading model...")

    # モデル読み込み
    pipe = pipeline(
        "automatic-speech-recognition",
        model=model_id,
        torch_dtype=torch_dtype,
        device=device,
        model_kwargs=model_kwargs
    )

    print("Model loaded successfully!")
    print("Loading audio file...")

    # 音声ファイルの読み込み (torchaudioを使用)
    waveform, sample_rate = torchaudio.load(input_file)
    print(f"Original sample rate: {sample_rate}Hz")
    print(f"Audio duration: {waveform.shape[-1]/sample_rate:.2f} seconds")

    # サンプリングレートの変換
    if sample_rate != 16000:
        print("Converting sample rate to 16kHz...")
        resample_waveform = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)(waveform)
    else:
        resample_waveform = waveform

    # PyTorch テンソルを NumPy 配列に変換
    resample_waveform_np = resample_waveform.numpy()

    # 変換実行
    print("Starting transcription...")
    start_time = time.time()
    result = pipe({"array": resample_waveform_np[0], "sampling_rate": 16000}, generate_kwargs=generate_kwargs)
    end_time = time.time()

    # 結果を保存
    output_file = "transcription.txt"
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(result["text"])

    print(f"\nTranscription saved to {output_file}")
    print(f"Processing time: {end_time - start_time:.2f} seconds")
    return result["text"]

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("input_file", help="音声ファイルのパス")
    args = parser.parse_args()

    try:
        transcribe_audio(args.input_file)
    except Exception as e:
        print(f"エラーが発生しました: {str(e)}")
        import traceback
        traceback.print_exc()

